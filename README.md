An advanced speech-to-text transcription system tailored for Urdu, built with state-of-the-art machine learning models like Whisper and T5.This project demonstrates the integration of language-specific pre-processing, model optimization, and evaluation techniques to achieve robust transcription accuracy.

Features Speech-to-Text Conversion: Converts Urdu audio files into accurate text transcriptions. Model Integration: Utilizes OpenAI's Whisper model for ASR and T5 for language fine-tuning. Pre-Processing Techniques: Handles noisy and multilingual datasets with advanced audio cleaning and tokenization strategies. Word Error Rate Analysis: Includes evaluation metrics to measure transcription accuracy and optimize pipeline performance.

git clone https://github.com/yourusername/urdu-asr-pipeline.git pip install -r requirements.txt

Download and prepare your dataset: Add your audio files to the data/audio/ folder. Transcriptions (if available) can go into data/text/.

Usage Preprocess Data: bash python preprocess.py --audio_dir data/audio --output_dir data/processed

Train or Fine-Tune Models: bash python train.py --config config.yaml

Evaluate Performance: bash python evaluate.py --model_path models/urdu_asr_model --test_data data/test

Results Word Error Rate (WER): Improved by fine-tuning tokenization and pre-processing. Achieved robust performance on noisy datasets and real-world Urdu audio inputs. Future Enhancements Support for other languages and dialects in the Urdu-speaking regions. Integration of real-time ASR capabilities using streaming APIs.

Contributing Contributions are welcome! Please open an issue or submit a pull request for any feature suggestions or bug fixes.
